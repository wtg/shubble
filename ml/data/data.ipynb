{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the complete data preprocessing pipeline for shuttle tracking data:\n",
    "1. Load vehicle locations from database/CSV\n",
    "2. Convert timestamps to epoch seconds\n",
    "3. Add closest route information\n",
    "4. Compute distance deltas\n",
    "5. Compute speed\n",
    "6. Segment into consecutive trips\n",
    "7. Visualize speed over time for a single segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import preprocessing functions\n",
    "from ml.pipelines import segment_pipeline\n",
    "from ml.data.preprocess import segment_by_consecutive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess Data\n",
    "\n",
    "The `preprocess_pipeline()` function runs all preprocessing steps and caches the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data (uses cache if available)\n",
    "df = segment_pipeline()\n",
    "\n",
    "print(f\"Loaded {len(df)} location points\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nData shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows surrounding largest speed\n",
    "max_speed_idx = df['speed_kmh'].idxmax()\n",
    "start_idx = max(0, max_speed_idx - 5)\n",
    "end_idx = min(len(df), max_speed_idx + 6)\n",
    "df.iloc[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Basic Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Number of vehicles: {df['vehicle_id'].nunique()}\")\n",
    "\n",
    "# Handle NaN values in route column\n",
    "route_values = df['route'].dropna().unique()\n",
    "print(f\"Number of routes: {len(route_values)}\")\n",
    "print(f\"\\nRoutes: {sorted(route_values)}\")\n",
    "\n",
    "# Count NaN routes\n",
    "nan_routes = df['route'].isna().sum()\n",
    "print(f\"Unmatched locations (no route): {nan_routes} ({nan_routes/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nSpeed statistics (km/h):\")\n",
    "print(df['speed_kmh'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Segment into Consecutive Trips\n",
    "\n",
    "Segments are created based on:\n",
    "- Vehicle ID changes\n",
    "- Time gaps > max_timedelta seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the data with 5-minute maximum time gap\n",
    "max_timedelta = 15\n",
    "segmented_df = segment_by_consecutive(df, max_timedelta=max_timedelta, segment_column='segment_id')\n",
    "\n",
    "num_segments = segmented_df['segment_id'].nunique()\n",
    "print(f\"Created {num_segments} segments with max time gap of {max_timedelta}s ({max_timedelta/60:.1f} minutes)\")\n",
    "\n",
    "# Segment size distribution\n",
    "segment_sizes = segmented_df.groupby('segment_id').size()\n",
    "print(f\"\\nSegment size statistics:\")\n",
    "print(segment_sizes.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot segment size distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "segment_sizes.hist(bins=50)\n",
    "plt.xlabel('Segment Size (number of points)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Segment Size Distribution')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "segment_sizes.hist(bins=50, cumulative=True, density=True)\n",
    "plt.xlabel('Segment Size (number of points)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.title('Cumulative Distribution')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSegments with >= 10 points: {(segment_sizes >= 10).sum()} ({(segment_sizes >= 10).sum() / len(segment_sizes) * 100:.1f}%)\")\n",
    "print(f\"Segments with >= 20 points: {(segment_sizes >= 20).sum()} ({(segment_sizes >= 20).sum() / len(segment_sizes) * 100:.1f}%)\")\n",
    "print(f\"Segments with >= 50 points: {(segment_sizes >= 50).sum()} ({(segment_sizes >= 50).sum() / len(segment_sizes) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Select and Visualize One Segment\n",
    "\n",
    "Let's select a segment with a reasonable number of points and visualize its speed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to segments with valid routes (no NaN)\n",
    "segmented_with_routes = segmented_df[segmented_df['route'].notna()].copy()\n",
    "valid_segment_sizes = segmented_with_routes.groupby('segment_id').size()\n",
    "\n",
    "# Find segments with at least 20 points for better visualization\n",
    "large_segments = valid_segment_sizes[valid_segment_sizes >= 20].index\n",
    "\n",
    "if len(large_segments) == 0:\n",
    "    print(\"No segments with >= 20 points and valid routes found. Using largest valid segment.\")\n",
    "    selected_segment_id = valid_segment_sizes.idxmax()\n",
    "else:\n",
    "    # Select a segment from the middle of the dataset\n",
    "    selected_segment_id = large_segments[len(large_segments) // 2]\n",
    "\n",
    "# Extract the selected segment\n",
    "segment = segmented_with_routes[segmented_with_routes['segment_id'] == selected_segment_id].copy()\n",
    "segment = segment.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Selected segment {selected_segment_id}\")\n",
    "print(f\"Number of points: {len(segment)}\")\n",
    "print(f\"Vehicle ID: {segment['vehicle_id'].iloc[0]}\")\n",
    "print(f\"Route: {segment['route'].iloc[0]}\")\n",
    "print(f\"Time range: {segment['timestamp'].iloc[0]} to {segment['timestamp'].iloc[-1]}\")\n",
    "print(f\"Duration: {(segment['timestamp'].iloc[-1] - segment['timestamp'].iloc[0]).total_seconds() / 60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display segment data\n",
    "segment[['vehicle_id', 'timestamp', 'latitude', 'longitude', 'route', 'distance_km', 'speed_kmh', 'epoch_seconds']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Speed Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Filter out NaN values for plotting\n",
    "segment_clean = segment[segment['speed_kmh'].notna()].copy()\n",
    "\n",
    "# Plot 1: Speed over time\n",
    "ax1 = axes[0]\n",
    "ax1.plot(segment_clean['timestamp'], segment_clean['speed_kmh'], marker='o', linestyle='-', linewidth=2, markersize=4)\n",
    "ax1.set_xlabel('Time', fontsize=12)\n",
    "ax1.set_ylabel('Speed (km/h)', fontsize=12)\n",
    "ax1.set_title(f'Speed Over Time - Segment {selected_segment_id} (Route: {segment[\"route\"].iloc[0]})', fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "mean_speed = segment_clean['speed_kmh'].mean()\n",
    "ax1.axhline(y=mean_speed, color='r', linestyle='--', label=f'Mean: {mean_speed:.2f} km/h')\n",
    "ax1.legend()\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Plot 2: Distance traveled over time (cumulative)\n",
    "ax2 = axes[1]\n",
    "cumulative_distance = segment_clean['distance_km'].cumsum()\n",
    "ax2.plot(segment_clean['timestamp'], cumulative_distance, marker='o', linestyle='-', linewidth=2, markersize=4, color='green')\n",
    "ax2.set_xlabel('Time', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Distance (km)', fontsize=12)\n",
    "ax2.set_title(f'Cumulative Distance Over Time - Segment {selected_segment_id}', fontsize=14, fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "total_distance = cumulative_distance.iloc[-1]\n",
    "ax2.text(0.02, 0.98, f'Total Distance: {total_distance:.2f} km',\n",
    "         transform=ax2.transAxes, fontsize=11, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSpeed Statistics for Segment {selected_segment_id}:\")\n",
    "print(f\"  Mean speed: {segment_clean['speed_kmh'].mean():.2f} km/h\")\n",
    "print(f\"  Median speed: {segment_clean['speed_kmh'].median():.2f} km/h\")\n",
    "print(f\"  Max speed: {segment_clean['speed_kmh'].max():.2f} km/h\")\n",
    "print(f\"  Min speed: {segment_clean['speed_kmh'].min():.2f} km/h\")\n",
    "print(f\"  Std dev: {segment_clean['speed_kmh'].std():.2f} km/h\")\n",
    "print(f\"  Total distance: {total_distance:.2f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Additional Visualization - Speed Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed distribution histogram (using clean data without NaN)\n",
    "segment_clean = segment[segment['speed_kmh'].notna()].copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(segment_clean['speed_kmh'], bins=20, edgecolor='black', alpha=0.7)\n",
    "mean_speed = segment_clean['speed_kmh'].mean()\n",
    "median_speed = segment_clean['speed_kmh'].median()\n",
    "plt.axvline(mean_speed, color='r', linestyle='--', linewidth=2, label=f'Mean: {mean_speed:.2f} km/h')\n",
    "plt.axvline(median_speed, color='g', linestyle='--', linewidth=2, label=f'Median: {median_speed:.2f} km/h')\n",
    "plt.xlabel('Speed (km/h)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title(f'Speed Distribution - Segment {selected_segment_id}', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Geographic Visualization (Optional)\n",
    "\n",
    "Plot the segment path on a simple coordinate plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the geographic path with speed as color (using clean data without NaN)\n",
    "segment_clean = segment[segment['speed_kmh'].notna()].copy()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a scatter plot with speed as color\n",
    "scatter = plt.scatter(segment_clean['longitude'], segment_clean['latitude'],\n",
    "                     c=segment_clean['speed_kmh'], cmap='RdYlGn',\n",
    "                     s=100, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add line connecting the points\n",
    "plt.plot(segment_clean['longitude'], segment_clean['latitude'],\n",
    "         color='blue', alpha=0.3, linewidth=1, linestyle='--')\n",
    "\n",
    "# Mark start and end\n",
    "plt.scatter(segment_clean['longitude'].iloc[0], segment_clean['latitude'].iloc[0],\n",
    "           color='green', s=200, marker='o', edgecolors='black', linewidth=2, label='Start', zorder=5)\n",
    "plt.scatter(segment_clean['longitude'].iloc[-1], segment_clean['latitude'].iloc[-1],\n",
    "           color='red', s=200, marker='s', edgecolors='black', linewidth=2, label='End', zorder=5)\n",
    "\n",
    "plt.colorbar(scatter, label='Speed (km/h)')\n",
    "plt.xlabel('Longitude', fontsize=12)\n",
    "plt.ylabel('Latitude', fontsize=12)\n",
    "plt.title(f'Geographic Path - Segment {selected_segment_id} (Route: {segment[\"route\"].iloc[0]})',\n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✓ Loading preprocessed vehicle location data\n",
    "2. ✓ Segmenting data into consecutive trips\n",
    "3. ✓ Visualizing speed over time for a single segment\n",
    "4. ✓ Analyzing speed distribution and geographic path\n",
    "5. ✓ **ETA analysis with stop information** (see below)\n",
    "\n",
    "The preprocessing pipeline handles:\n",
    "- Timestamp conversion to epoch seconds\n",
    "- Route matching using closest point algorithm\n",
    "- Distance calculation between consecutive points\n",
    "- Speed calculation from distance and time\n",
    "- Segmentation based on vehicle ID and time gaps\n",
    "- Stop detection and ETA calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ETA pipeline (handles segmentation, stop detection, filtering, and ETA calculation)\n",
    "from ml.pipelines import stops_pipeline\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RUNNING ETA PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "stops_df = stops_pipeline()\n",
    "\n",
    "print(f\"\\nFinal ETA data:\")\n",
    "print(f\"  Total points: {len(stops_df):,}\")\n",
    "print(f\"  Total segments: {stops_df['segment_id'].nunique():,}\")\n",
    "print(f\"\\nColumns in ETA data:\")\n",
    "print(f\"  {list(stops_df.columns)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nSample data with stop and ETA information:\")\n",
    "stops_df[['timestamp', 'vehicle_id', 'route', 'stop_name', 'stop_route', 'speed_kmh']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the ETA pipeline results\n",
    "print(\"=\"*70)\n",
    "print(\"ETA PIPELINE STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Stop information\n",
    "points_with_stops = stops_df['stop_name'].notna().sum()\n",
    "points_without_stops = stops_df['stop_name'].isna().sum()\n",
    "print(f\"\\nStop Detection:\")\n",
    "print(f\"  Points at stops: {points_with_stops:,} ({points_with_stops/len(stops_df)*100:.2f}%)\")\n",
    "print(f\"  Points not at stops: {points_without_stops:,} ({points_without_stops/len(stops_df)*100:.2f}%)\")\n",
    "print(f\"  Unique stops visited: {stops_df['stop_name'].nunique()}\")\n",
    "# List all unique stops\n",
    "print(f\"\\nAll stops in dataset:\")\n",
    "for stop in sorted(stops_df['stop_name'].dropna().unique()):\n",
    "    count = (stops_df['stop_name'] == stop).sum()\n",
    "    print(f\"  - {stop}: {count:,} visits\")\n",
    "\n",
    "# ETA information\n",
    "eta_calculated = stops_df['eta_seconds'].notna().sum()\n",
    "eta_null = stops_df['eta_seconds'].isna().sum()\n",
    "print(f\"\\nETA Calculation:\")\n",
    "print(f\"  ETAs calculated: {eta_calculated:,} ({eta_calculated/len(stops_df)*100:.2f}%)\")\n",
    "print(f\"  NULL ETAs: {eta_null:,} ({eta_null/len(stops_df)*100:.2f}%)\")\n",
    "print(f\"  (NULL ETAs occur after the last stop in each segment)\")\n",
    "\n",
    "# ETA statistics\n",
    "eta_values = stops_df['eta_seconds'].dropna()\n",
    "print(f\"\\nETA Distribution (seconds):\")\n",
    "print(eta_values.describe())\n",
    "print(f\"\\nETA Distribution (minutes):\")\n",
    "print((eta_values / 60).describe())\n",
    "\n",
    "# Segment information\n",
    "segments_in_eta_data = stops_df['segment_id'].nunique()\n",
    "print(f\"\\nSegments in ETA data: {segments_in_eta_data:,}\")\n",
    "print(f\"  (These are segments that passed through at least one stop)\")\n",
    "\n",
    "# Compare to original segmented data\n",
    "original_df = segment_pipeline()\n",
    "original_segments = original_df['segment_id'].nunique()\n",
    "filtered_segments = original_segments - segments_in_eta_data\n",
    "print(f\"\\nSegment Filtering:\")\n",
    "print(f\"  Original segments (from segment_pipeline): {original_segments:,}\")\n",
    "print(f\"  Segments with stops (in ETA data): {segments_in_eta_data:,} ({segments_in_eta_data/original_segments*100:.2f}%)\")\n",
    "print(f\"  Segments filtered out (no stops): {filtered_segments:,} ({filtered_segments/original_segments*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize ETA for a Segment with Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a segment with multiple stops for better visualization\n",
    "segment_stop_counts = stops_df.groupby('segment_id')['stop_name'].apply(lambda x: x.notna().sum())\n",
    "segments_with_multiple_stops = segment_stop_counts[segment_stop_counts >= 2].index\n",
    "\n",
    "if len(segments_with_multiple_stops) > 0:\n",
    "    # Select a segment from the middle\n",
    "    selected_eta_segment_id = segments_with_multiple_stops[len(segments_with_multiple_stops) // 2]\n",
    "else:\n",
    "    # Fallback to any segment with at least one stop\n",
    "    segments_with_stops = segment_stop_counts[segment_stop_counts >= 1].index\n",
    "    selected_eta_segment_id = segments_with_stops[len(segments_with_stops) // 2] if len(segments_with_stops) > 0 else stops_df['segment_id'].iloc[0]\n",
    "\n",
    "# Extract the segment\n",
    "eta_segment = stops_df[stops_df['segment_id'] == selected_eta_segment_id].copy()\n",
    "eta_segment = eta_segment.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Selected segment {selected_eta_segment_id} for ETA visualization\")\n",
    "print(f\"Number of points: {len(eta_segment)}\")\n",
    "print(f\"Points at stops: {eta_segment['stop_name'].notna().sum()}\")\n",
    "print(f\"Unique stops visited: {eta_segment['stop_name'].nunique()}\")\n",
    "print(f\"ETAs calculated: {eta_segment['eta_seconds'].notna().sum()}\")\n",
    "print(f\"Route: {eta_segment['route'].iloc[0]}\")\n",
    "print(f\"\\nStops in this segment:\")\n",
    "stops_in_segment = eta_segment[eta_segment['stop_name'].notna()][['timestamp', 'stop_name', 'stop_route']].drop_duplicates()\n",
    "for idx, row in stops_in_segment.iterrows():\n",
    "    print(f\"  - {row['stop_name']} ({row['stop_route']}) at {row['timestamp']}\")\n",
    "\n",
    "# Display segment with ETA information\n",
    "print(f\"\\nSegment data with ETAs:\")\n",
    "eta_segment[['timestamp', 'latitude', 'longitude', 'stop_name', 'eta_seconds', 'speed_kmh']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization: ETA Pipeline Results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Get original segment count for comparison\n",
    "original_df = segment_pipeline()\n",
    "original_segments = original_df['segment_id'].nunique()\n",
    "segments_in_eta = stops_df['segment_id'].nunique()\n",
    "segments_filtered = original_segments - segments_in_eta\n",
    "\n",
    "# Get statistics\n",
    "points_with_stops = stops_df['stop_name'].notna().sum()\n",
    "points_without_stops = stops_df['stop_name'].isna().sum()\n",
    "eta_calculated = stops_df['eta_seconds'].notna().sum()\n",
    "eta_null = stops_df['eta_seconds'].isna().sum()\n",
    "\n",
    "# Plot 1: Segment filtering\n",
    "ax1 = axes[0]\n",
    "segment_categories = ['Original\\nSegments', 'Segments\\nwith Stops', 'Segments\\nFiltered Out']\n",
    "segment_counts = [original_segments, segments_in_eta, segments_filtered]\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "bars1 = ax1.bar(segment_categories, segment_counts, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_ylabel('Number of Segments', fontsize=12)\n",
    "ax1.set_title('Segment Filtering', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 2: Points at stops vs not at stops\n",
    "ax2 = axes[1]\n",
    "point_categories = ['Points\\nat Stops', 'Points\\nNot at Stops']\n",
    "point_counts = [points_with_stops, points_without_stops]\n",
    "colors2 = ['#2ecc71', '#95a5a6']\n",
    "bars2 = ax2.bar(point_categories, point_counts, color=colors2, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_ylabel('Number of Points', fontsize=12)\n",
    "ax2.set_title('Stop Detection Results', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels and percentages\n",
    "for bar, count in zip(bars2, point_counts):\n",
    "    height = bar.get_height()\n",
    "    percentage = count / len(stops_df) * 100\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(count):,}\\n({percentage:.1f}%)',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 3: ETA calculation results\n",
    "ax3 = axes[2]\n",
    "eta_categories = ['ETAs\\nCalculated', 'NULL\\nETAs']\n",
    "eta_counts = [eta_calculated, eta_null]\n",
    "colors3 = ['#9b59b6', '#e67e22']\n",
    "bars3 = ax3.bar(eta_categories, eta_counts, color=colors3, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_ylabel('Number of Points', fontsize=12)\n",
    "ax3.set_title('ETA Calculation Results', fontsize=14, fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels and percentages\n",
    "for bar, count in zip(bars3, eta_counts):\n",
    "    height = bar.get_height()\n",
    "    percentage = count / len(stops_df) * 100\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(count):,}\\n({percentage:.1f}%)',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ETA PIPELINE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original segments:              {original_segments:,}\")\n",
    "print(f\"Segments with stops:            {segments_in_eta:,} ({segments_in_eta/original_segments*100:.1f}%)\")\n",
    "print(f\"Segments filtered out:          {segments_filtered:,} ({segments_filtered/original_segments*100:.1f}%)\")\n",
    "print(f\"\\nTotal points in ETA data:       {len(stops_df):,}\")\n",
    "print(f\"Points at stops:                {points_with_stops:,} ({points_with_stops/len(stops_df)*100:.1f}%)\")\n",
    "print(f\"Points not at stops:            {points_without_stops:,} ({points_without_stops/len(stops_df)*100:.1f}%)\")\n",
    "print(f\"\\nETAs calculated:                {eta_calculated:,} ({eta_calculated/len(stops_df)*100:.1f}%)\")\n",
    "print(f\"NULL ETAs:                      {eta_null:,} ({eta_null/len(stops_df)*100:.1f}%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the segment with the maximum eta\n",
    "max_eta_idx = stops_df['eta_seconds'].idxmax()\n",
    "segment_with_max_eta = stops_df[stops_df['segment_id'] == stops_df.loc[max_eta_idx, 'segment_id']].copy()\n",
    "segment_with_max_eta = segment_with_max_eta.sort_values('timestamp')\n",
    "segment_with_max_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ETA over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Filter to points with ETAs\n",
    "eta_segment_clean = eta_segment[eta_segment['eta_seconds'].notna()].copy()\n",
    "\n",
    "# Plot 1: ETA to next stop over time\n",
    "ax1 = axes[0]\n",
    "ax1.plot(eta_segment_clean['timestamp'], eta_segment_clean['eta_seconds'],\n",
    "         marker='o', linestyle='-', linewidth=2, markersize=4, color='purple')\n",
    "ax1.set_xlabel('Time', fontsize=12)\n",
    "ax1.set_ylabel('ETA to Next Stop (seconds)', fontsize=12)\n",
    "ax1.set_title(f'ETA Over Time - Segment {selected_eta_segment_id}', fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Highlight points at stops\n",
    "stops_mask = eta_segment_clean['stop_name'].notna()\n",
    "if stops_mask.any():\n",
    "    ax1.scatter(eta_segment_clean[stops_mask]['timestamp'],\n",
    "               eta_segment_clean[stops_mask]['eta_seconds'],\n",
    "               color='red', s=150, marker='*', label='At Stop', zorder=5)\n",
    "    ax1.legend()\n",
    "\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Plot 2: ETA vs Speed\n",
    "ax2 = axes[1]\n",
    "# Filter to points with both ETA and speed\n",
    "plot_data = eta_segment[(eta_segment['eta_seconds'].notna()) & (eta_segment['speed_kmh'].notna())].copy()\n",
    "\n",
    "if len(plot_data) > 0:\n",
    "    ax2_twin = ax2.twinx()\n",
    "\n",
    "    # Plot ETA on left y-axis\n",
    "    line1 = ax2.plot(plot_data['timestamp'], plot_data['eta_seconds'],\n",
    "                     marker='o', linestyle='-', linewidth=2, markersize=4,\n",
    "                     color='purple', label='ETA (seconds)')\n",
    "    ax2.set_ylabel('ETA to Next Stop (seconds)', fontsize=12, color='purple')\n",
    "    ax2.tick_params(axis='y', labelcolor='purple')\n",
    "\n",
    "    # Plot speed on right y-axis\n",
    "    line2 = ax2_twin.plot(plot_data['timestamp'], plot_data['speed_kmh'],\n",
    "                          marker='s', linestyle='-', linewidth=2, markersize=4,\n",
    "                          color='blue', label='Speed (km/h)', alpha=0.7)\n",
    "    ax2_twin.set_ylabel('Speed (km/h)', fontsize=12, color='blue')\n",
    "    ax2_twin.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    ax2.set_xlabel('Time', fontsize=12)\n",
    "    ax2.set_title(f'ETA vs Speed - Segment {selected_eta_segment_id}', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "    # Combine legends\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax2.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "if len(eta_segment_clean) > 0:\n",
    "    print(f\"\\nETA Statistics for Segment {selected_eta_segment_id}:\")\n",
    "    print(f\"  Mean ETA: {eta_segment_clean['eta_seconds'].mean():.2f} seconds ({eta_segment_clean['eta_seconds'].mean()/60:.2f} minutes)\")\n",
    "    print(f\"  Median ETA: {eta_segment_clean['eta_seconds'].median():.2f} seconds ({eta_segment_clean['eta_seconds'].median()/60:.2f} minutes)\")\n",
    "    print(f\"  Max ETA: {eta_segment_clean['eta_seconds'].max():.2f} seconds ({eta_segment_clean['eta_seconds'].max()/60:.2f} minutes)\")\n",
    "    print(f\"  Min ETA: {eta_segment_clean['eta_seconds'].min():.2f} seconds ({eta_segment_clean['eta_seconds'].min()/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The ETA pipeline analysis shows:\n",
    "- **Stop Detection**: A significant portion of segments pass through known stops\n",
    "- **Segment Filtering**: Segments without any stops are filtered out, focusing the dataset on meaningful trip segments\n",
    "- **ETA Calculation**: Most points have valid ETAs to the next stop, with NULL values primarily occurring after the final stop in each segment\n",
    "- **Data Quality**: The pipeline effectively identifies stops and calculates realistic ETAs that can be used for machine learning prediction tasks\n",
    "\n",
    "The data is now ready for LSTM and ARIMA model training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases for clean_stops() function\n",
    "- **Test Case 1**: Current/next point distance is closer to stop than previous point\n",
    "- **Test Case 2**: Previous point distance is closer to stop than current/next point\n",
    "- **Test Case 3**: Tie (current point always wins ties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for `clean_stops` using ROUTES data\n",
    "# Test Case 1: curr_distance is CLOSER to the stop\n",
    "# Builds a DataFrame composed of: first polyline minus its last two points,\n",
    "# then the first point of the next polyline. Then runs `clean_stops`.\n",
    "import json\n",
    "import pandas as pd\n",
    "from ml.data.preprocess import clean_stops\n",
    "\n",
    "routes_file = project_root / 'shared' / 'routes.json'\n",
    "with open(routes_file, 'r', encoding='utf-8') as f:\n",
    "    routes = json.load(f)\n",
    "\n",
    "# Choose first route in the file\n",
    "route_key = list(routes.keys())[0]\n",
    "polylines = routes[route_key]['ROUTES']\n",
    "\n",
    "# Defensive checks\n",
    "if len(polylines) < 2:\n",
    "    raise RuntimeError('Expected at least two polylines in the chosen route for this test')\n",
    "\n",
    "first_poly = polylines[0]\n",
    "second_poly = polylines[1]\n",
    "\n",
    "# Take first polyline minus its last two points, then append the first point of next polyline\n",
    "if len(first_poly) >= 3:\n",
    "    coords = first_poly[:-2]\n",
    "else:\n",
    "    coords = first_poly.copy()\n",
    "coords.append(second_poly[0])\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(coords, columns=['lat', 'lon'])\n",
    "# All rows have same route name\n",
    "df['route'] = route_key\n",
    "# polyline idx: 0 for points from first polyline, 1 for the appended point\n",
    "df['polyline_idx'] = [0] * (len(df) - 1) + [1]\n",
    "# Initially no stops recorded\n",
    "df['stop'] = pd.NA\n",
    "# Distances: earlier points set far, last point set very close (so the closer coordinate should be labeled)\n",
    "df['dist'] = [0.05] * (len(df) - 1) + [0.001]\n",
    "\n",
    "print('Before clean_stops:')\n",
    "print(df[['lat','lon','polyline_idx','dist','stop']])\n",
    "\n",
    "# Run the function under test\n",
    "clean_stops(\n",
    "    df,\n",
    "    route_column='route',\n",
    "    polyline_index_column='polyline_idx',\n",
    "    stop_column='stop',\n",
    "    lat_column='lat',\n",
    "    lon_column='lon',\n",
    "    distance_column='dist'\n",
    ")\n",
    "\n",
    "print('\\nAfter clean_stops:')\n",
    "print(df[['lat','lon','polyline_idx','dist','stop']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST CASE 2: prev_distance is CLOSER (0.001 vs 0.05)\n",
      "======================================================================\n",
      "Before clean_stops:\n",
      "          lat        lon  polyline_idx   dist  stop\n",
      "0   42.730711 -73.676737             0  0.001  <NA>\n",
      "1   42.730711 -73.676737             0  0.001  <NA>\n",
      "2   42.730676 -73.676552             0  0.001  <NA>\n",
      "3   42.730606 -73.676315             0  0.001  <NA>\n",
      "4   42.730531 -73.676165             0  0.001  <NA>\n",
      "5   42.730398 -73.675924             0  0.001  <NA>\n",
      "6   42.730352 -73.675786             0  0.001  <NA>\n",
      "7   42.730189 -73.675337             0  0.001  <NA>\n",
      "8   42.730112 -73.675185             0  0.001  <NA>\n",
      "9   42.730085 -73.675131             0  0.001  <NA>\n",
      "10  42.730085 -73.675131             0  0.001  <NA>\n",
      "11  42.730231 -73.674884             0  0.001  <NA>\n",
      "12  42.730353 -73.674630             0  0.001  <NA>\n",
      "13  42.730414 -73.674369             0  0.001  <NA>\n",
      "14  42.730460 -73.674251             0  0.001  <NA>\n",
      "15  42.730831 -73.673825             0  0.001  <NA>\n",
      "16  42.730942 -73.673636             0  0.001  <NA>\n",
      "17  42.730982 -73.673525             0  0.001  <NA>\n",
      "18  42.731052 -73.673139             0  0.001  <NA>\n",
      "19  42.731154 -73.672631             0  0.001  <NA>\n",
      "20  42.731350 -73.672027             0  0.001  <NA>\n",
      "21  42.731367 -73.671978             0  0.001  <NA>\n",
      "22  42.731367 -73.671978             0  0.001  <NA>\n",
      "23  42.731561 -73.671924             0  0.001  <NA>\n",
      "24  42.732407 -73.671688             0  0.001  <NA>\n",
      "25  42.733623 -73.671347             0  0.001  <NA>\n",
      "26  42.734017 -73.671238             0  0.001  <NA>\n",
      "27  42.734622 -73.671072             0  0.001  <NA>\n",
      "28  42.735645 -73.670785             0  0.001  <NA>\n",
      "29  42.735721 -73.670764             0  0.001  <NA>\n",
      "30  42.736457 -73.670561             0  0.001  <NA>\n",
      "31  42.737048 -73.670397             1  0.050  <NA>\n",
      "   Found 1 unrecorded stop jumps\n",
      "   ✓ Assigned 1 unrecorded stops\n",
      "\n",
      "After clean_stops:\n",
      "          lat        lon  polyline_idx   dist     stop\n",
      "0   42.730711 -73.676737             0  0.001     <NA>\n",
      "1   42.730711 -73.676737             0  0.001     <NA>\n",
      "2   42.730676 -73.676552             0  0.001     <NA>\n",
      "3   42.730606 -73.676315             0  0.001     <NA>\n",
      "4   42.730531 -73.676165             0  0.001     <NA>\n",
      "5   42.730398 -73.675924             0  0.001     <NA>\n",
      "6   42.730352 -73.675786             0  0.001     <NA>\n",
      "7   42.730189 -73.675337             0  0.001     <NA>\n",
      "8   42.730112 -73.675185             0  0.001     <NA>\n",
      "9   42.730085 -73.675131             0  0.001     <NA>\n",
      "10  42.730085 -73.675131             0  0.001     <NA>\n",
      "11  42.730231 -73.674884             0  0.001     <NA>\n",
      "12  42.730353 -73.674630             0  0.001     <NA>\n",
      "13  42.730414 -73.674369             0  0.001     <NA>\n",
      "14  42.730460 -73.674251             0  0.001     <NA>\n",
      "15  42.730831 -73.673825             0  0.001     <NA>\n",
      "16  42.730942 -73.673636             0  0.001     <NA>\n",
      "17  42.730982 -73.673525             0  0.001     <NA>\n",
      "18  42.731052 -73.673139             0  0.001     <NA>\n",
      "19  42.731154 -73.672631             0  0.001     <NA>\n",
      "20  42.731350 -73.672027             0  0.001     <NA>\n",
      "21  42.731367 -73.671978             0  0.001     <NA>\n",
      "22  42.731367 -73.671978             0  0.001     <NA>\n",
      "23  42.731561 -73.671924             0  0.001     <NA>\n",
      "24  42.732407 -73.671688             0  0.001     <NA>\n",
      "25  42.733623 -73.671347             0  0.001     <NA>\n",
      "26  42.734017 -73.671238             0  0.001     <NA>\n",
      "27  42.734622 -73.671072             0  0.001     <NA>\n",
      "28  42.735645 -73.670785             0  0.001     <NA>\n",
      "29  42.735721 -73.670764             0  0.001     <NA>\n",
      "30  42.736457 -73.670561             0  0.001  COLONIE\n",
      "31  42.737048 -73.670397             1  0.050     <NA>\n",
      "\n",
      "✓ Expected: stop should be assigned to row with prev_distance (0.001), NOT the last row\n"
     ]
    }
   ],
   "source": [
    "# Test Case 2: prev_distance is CLOSER to the stop\n",
    "# The stop should be assigned to the PREVIOUS row (shifted assignment)\n",
    "import json\n",
    "import pandas as pd\n",
    "from ml.data.preprocess import clean_stops\n",
    "\n",
    "routes_file = project_root / 'shared' / 'routes.json'\n",
    "with open(routes_file, 'r', encoding='utf-8') as f:\n",
    "    routes = json.load(f)\n",
    "\n",
    "route_key = list(routes.keys())[0]\n",
    "polylines = routes[route_key]['ROUTES']\n",
    "\n",
    "if len(polylines) < 2:\n",
    "    raise RuntimeError('Expected at least two polylines')\n",
    "\n",
    "first_poly = polylines[0]\n",
    "second_poly = polylines[1]\n",
    "\n",
    "if len(first_poly) >= 3:\n",
    "    coords = first_poly[:-2]\n",
    "else:\n",
    "    coords = first_poly.copy()\n",
    "coords.append(second_poly[0])\n",
    "\n",
    "df2 = pd.DataFrame(coords, columns=['lat', 'lon'])\n",
    "df2['route'] = route_key\n",
    "df2['polyline_idx'] = [0] * (len(df2) - 1) + [1]\n",
    "df2['stop'] = pd.NA\n",
    "# Key difference: prev distance is CLOSE (0.001), current is FAR (0.05)\n",
    "df2['dist'] = [0.001] * (len(df2) - 1) + [0.05]\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('TEST CASE 2: prev_distance is CLOSER (0.001 vs 0.05)')\n",
    "print('='*70)\n",
    "print('Before clean_stops:')\n",
    "print(df2[['lat','lon','polyline_idx','dist','stop']])\n",
    "\n",
    "clean_stops(\n",
    "    df2,\n",
    "    route_column='route',\n",
    "    polyline_index_column='polyline_idx',\n",
    "    stop_column='stop',\n",
    "    lat_column='lat',\n",
    "    lon_column='lon',\n",
    "    distance_column='dist'\n",
    ")\n",
    "\n",
    "print('\\nAfter clean_stops:')\n",
    "print(df2[['lat','lon','polyline_idx','dist','stop']])\n",
    "print('\\n✓ Expected: stop should be assigned to row with prev_distance (0.001), NOT the last row')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST CASE 4: prev_distance EQUALS current_distance (tie)\n",
      "======================================================================\n",
      "Before clean_stops:\n",
      "          lat        lon  polyline_idx   dist  stop\n",
      "0   42.730711 -73.676737             0  0.025  <NA>\n",
      "1   42.730711 -73.676737             0  0.025  <NA>\n",
      "2   42.730676 -73.676552             0  0.025  <NA>\n",
      "3   42.730606 -73.676315             0  0.025  <NA>\n",
      "4   42.730531 -73.676165             0  0.025  <NA>\n",
      "5   42.730398 -73.675924             0  0.025  <NA>\n",
      "6   42.730352 -73.675786             0  0.025  <NA>\n",
      "7   42.730189 -73.675337             0  0.025  <NA>\n",
      "8   42.730112 -73.675185             0  0.025  <NA>\n",
      "9   42.730085 -73.675131             0  0.025  <NA>\n",
      "10  42.730085 -73.675131             0  0.025  <NA>\n",
      "11  42.730231 -73.674884             0  0.025  <NA>\n",
      "12  42.730353 -73.674630             0  0.025  <NA>\n",
      "13  42.730414 -73.674369             0  0.025  <NA>\n",
      "14  42.730460 -73.674251             0  0.025  <NA>\n",
      "15  42.730831 -73.673825             0  0.025  <NA>\n",
      "16  42.730942 -73.673636             0  0.025  <NA>\n",
      "17  42.730982 -73.673525             0  0.025  <NA>\n",
      "18  42.731052 -73.673139             0  0.025  <NA>\n",
      "19  42.731154 -73.672631             0  0.025  <NA>\n",
      "20  42.731350 -73.672027             0  0.025  <NA>\n",
      "21  42.731367 -73.671978             0  0.025  <NA>\n",
      "22  42.731367 -73.671978             0  0.025  <NA>\n",
      "23  42.731561 -73.671924             0  0.025  <NA>\n",
      "24  42.732407 -73.671688             0  0.025  <NA>\n",
      "25  42.733623 -73.671347             0  0.025  <NA>\n",
      "26  42.734017 -73.671238             0  0.025  <NA>\n",
      "27  42.734622 -73.671072             0  0.025  <NA>\n",
      "28  42.735645 -73.670785             0  0.025  <NA>\n",
      "29  42.735721 -73.670764             0  0.025  <NA>\n",
      "30  42.736457 -73.670561             0  0.025  <NA>\n",
      "31  42.737048 -73.670397             1  0.025  <NA>\n",
      "   Found 1 unrecorded stop jumps\n",
      "   ✓ Assigned 1 unrecorded stops\n",
      "\n",
      "After clean_stops:\n",
      "          lat        lon  polyline_idx   dist     stop\n",
      "0   42.730711 -73.676737             0  0.025     <NA>\n",
      "1   42.730711 -73.676737             0  0.025     <NA>\n",
      "2   42.730676 -73.676552             0  0.025     <NA>\n",
      "3   42.730606 -73.676315             0  0.025     <NA>\n",
      "4   42.730531 -73.676165             0  0.025     <NA>\n",
      "5   42.730398 -73.675924             0  0.025     <NA>\n",
      "6   42.730352 -73.675786             0  0.025     <NA>\n",
      "7   42.730189 -73.675337             0  0.025     <NA>\n",
      "8   42.730112 -73.675185             0  0.025     <NA>\n",
      "9   42.730085 -73.675131             0  0.025     <NA>\n",
      "10  42.730085 -73.675131             0  0.025     <NA>\n",
      "11  42.730231 -73.674884             0  0.025     <NA>\n",
      "12  42.730353 -73.674630             0  0.025     <NA>\n",
      "13  42.730414 -73.674369             0  0.025     <NA>\n",
      "14  42.730460 -73.674251             0  0.025     <NA>\n",
      "15  42.730831 -73.673825             0  0.025     <NA>\n",
      "16  42.730942 -73.673636             0  0.025     <NA>\n",
      "17  42.730982 -73.673525             0  0.025     <NA>\n",
      "18  42.731052 -73.673139             0  0.025     <NA>\n",
      "19  42.731154 -73.672631             0  0.025     <NA>\n",
      "20  42.731350 -73.672027             0  0.025     <NA>\n",
      "21  42.731367 -73.671978             0  0.025     <NA>\n",
      "22  42.731367 -73.671978             0  0.025     <NA>\n",
      "23  42.731561 -73.671924             0  0.025     <NA>\n",
      "24  42.732407 -73.671688             0  0.025     <NA>\n",
      "25  42.733623 -73.671347             0  0.025     <NA>\n",
      "26  42.734017 -73.671238             0  0.025     <NA>\n",
      "27  42.734622 -73.671072             0  0.025     <NA>\n",
      "28  42.735645 -73.670785             0  0.025     <NA>\n",
      "29  42.735721 -73.670764             0  0.025     <NA>\n",
      "30  42.736457 -73.670561             0  0.025     <NA>\n",
      "31  42.737048 -73.670397             1  0.025  COLONIE\n",
      "\n",
      "✓ Expected: on tie (equal distances), current_distance wins (>= operator), so stop on last row\n"
     ]
    }
   ],
   "source": [
    "# Test Case 3: prev_distance EQUALS current_distance (tie scenario)\n",
    "# According to the code: prev_closer_mask = (df['prev_distance'] < df[distance_column])\n",
    "# When equal, prev_closer_mask is False, so next_closer_mask (>=) will be True\n",
    "# Stop should be assigned to the CURRENT (last) row\n",
    "import json\n",
    "import pandas as pd\n",
    "from ml.data.preprocess import clean_stops\n",
    "\n",
    "routes_file = project_root / 'shared' / 'routes.json'\n",
    "with open(routes_file, 'r', encoding='utf-8') as f:\n",
    "    routes = json.load(f)\n",
    "\n",
    "route_key = list(routes.keys())[0]\n",
    "polylines = routes[route_key]['ROUTES']\n",
    "\n",
    "if len(polylines) < 2:\n",
    "    raise RuntimeError('Expected at least two polylines')\n",
    "\n",
    "first_poly = polylines[0]\n",
    "second_poly = polylines[1]\n",
    "\n",
    "if len(first_poly) >= 3:\n",
    "    coords = first_poly[:-2]\n",
    "else:\n",
    "    coords = first_poly.copy()\n",
    "coords.append(second_poly[0])\n",
    "\n",
    "df4 = pd.DataFrame(coords, columns=['lat', 'lon'])\n",
    "df4['route'] = route_key\n",
    "df4['polyline_idx'] = [0] * (len(df4) - 1) + [1]\n",
    "df4['stop'] = pd.NA\n",
    "# Key: both distances are the SAME (0.025)\n",
    "df4['dist'] = [0.025] * len(df4)\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('TEST CASE 4: prev_distance EQUALS current_distance (tie)')\n",
    "print('='*70)\n",
    "print('Before clean_stops:')\n",
    "print(df4[['lat','lon','polyline_idx','dist','stop']])\n",
    "\n",
    "clean_stops(\n",
    "    df4,\n",
    "    route_column='route',\n",
    "    polyline_index_column='polyline_idx',\n",
    "    stop_column='stop',\n",
    "    lat_column='lat',\n",
    "    lon_column='lon',\n",
    "    distance_column='dist'\n",
    ")\n",
    "\n",
    "print('\\nAfter clean_stops:')\n",
    "print(df4[['lat','lon','polyline_idx','dist','stop']])\n",
    "print('\\n✓ Expected: on tie (equal distances), current_distance wins (>= operator), so stop on last row')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shubble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
